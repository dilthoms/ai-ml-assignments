{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of kaggle-digits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilthoms/ai-ml-assignments/blob/master/kaggle/kaggle-digits/kaggle-digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "soMh_oOhlHD3"
      },
      "source": [
        "# 1. Setup kaggle cli and download dataset in google colab\n",
        "\n",
        "Since all data is lost when google colab session ends, the six steps given below will download dataset from kaggle and save you from the trouble of downloading the dataset everytime. The first two steps below have to be done manually the first time. After that the rest of the steps can be executed by running the three cells (steps 3-6) below. You have to run these three cells to download the dataset everytime you start a new session. \n",
        "  \n",
        "\n",
        "1. Download / create json credentials after creating an account in kaggle.  See https://github.com/Kaggle/kaggle-api for more details\n",
        "2. Upload the kaggle.json file to your google drive\n",
        "3. Run the script in the first cell below to download kaggle.json  to your colab environment\n",
        "4. It will ask you to click on a link and enter the verification code\n",
        "5. Install kaggle cli using pip install\n",
        "6. Download the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zUM5cK52lHD6",
        "outputId": "07928841-33c5-4cc0-e737-c03f2b9906bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Code from https://medium.com/@move37timm/using-kaggle-api-for-google-colaboratory-d18645f93648\n",
        "# Create kaggle.json by following instructions at https://github.com/Kaggle/kaggle-api\n",
        "# Upload kaggle.json to google drive\n",
        "# Download kaggle.json to colab from the users google drive\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "if not os.path.exists(os.path.dirname(filename)):\n",
        "  os.makedirs(os.path.dirname(filename))\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9KPWpND0lHD-",
        "outputId": "ea06fa5f-4ec0-4493-a29d-192c0ffc764a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Install kaggle cli\n",
        "!pip install kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBU3yAwLlHEB",
        "outputId": "affce3e6-9fb5-4a9f-a900-a3e997424ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Download the dataset for digit-recognizer chalenge\n",
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 55% 5.00M/9.16M [00:00<00:00, 34.6MB/s]\n",
            "100% 9.16M/9.16M [00:00<00:00, 44.8MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 82% 5.00M/6.09M [00:00<00:00, 32.7MB/s]\n",
            "100% 6.09M/6.09M [00:00<00:00, 29.8MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 65.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxHZ6ewrX4sA",
        "colab_type": "text"
      },
      "source": [
        "# 2. Read data in pandas dataframe\n",
        "1. Check train and test csv files have been downloaded\n",
        "2. import pandas and numpy and create train and test dataframes from the respective csv files\n",
        "3. Inspect the dataframes\n",
        "4. Convert to numpy arrays for train, validation, and test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ8a8xpkX4sB",
        "colab_type": "code",
        "outputId": "fd5fc65c-2efe-4fee-b84a-060bbffd51a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Check train and test csv files exist\n",
        "!ls -ltr\n",
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 15864\n",
            "drwxr-xr-x 1 root root    4096 Dec 18 16:52 sample_data\n",
            "-rw-r--r-- 1 root root    2608 Jan 12 15:48 adc.json\n",
            "-rw-r--r-- 1 root root 9606023 Jan 12 15:48 train.csv.zip\n",
            "-rw-r--r-- 1 root root 6385593 Jan 12 15:48 test.csv.zip\n",
            "-rw-r--r-- 1 root root  240909 Jan 12 15:48 sample_submission.csv\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDRoZUpkX4sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the csv files using pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df_tr = pd.read_csv('train.csv')\n",
        "df_te = pd.read_csv('test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg_CeJieX4sF",
        "colab_type": "code",
        "outputId": "64fef786-b0f3-4424-b203-ebedb40a71de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "# Examine the contents of train.csv\n",
        "# Contains 28x28 pixel values and the corresponding digit label\n",
        "print (df_tr.info())\n",
        "df_tr.head()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42000 entries, 0 to 41999\n",
            "Columns: 785 entries, label to pixel783\n",
            "dtypes: int64(785)\n",
            "memory usage: 251.5 MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3VnaQQmX4sH",
        "colab_type": "code",
        "outputId": "8e72aae1-3836-4a69-a8ec-d5b739ec30f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "# Examine the contents of test.csv\n",
        "# Contains only the 28x28 pixel values without the corresponding digit label\n",
        "print (df_te.info())\n",
        "df_te.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28000 entries, 0 to 27999\n",
            "Columns: 784 entries, pixel0 to pixel783\n",
            "dtypes: int64(784)\n",
            "memory usage: 167.5 MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0       0       0       0       0  ...         0         0         0         0\n",
              "1       0       0       0       0  ...         0         0         0         0\n",
              "2       0       0       0       0  ...         0         0         0         0\n",
              "3       0       0       0       0  ...         0         0         0         0\n",
              "4       0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sewFQiFaX4sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Partition the training data into pixels (independent variable) and label (dependent variable)\n",
        "X = np.asarray(df_tr.drop('label',axis=1),dtype=np.uint8).reshape(-1,28,28)\n",
        "yhat = np.asarray(df_tr['label'])\n",
        "\n",
        "np.random.seed(2)\n",
        "# Generate random indices for creating a random validation set with 20% of the labelled data\n",
        "validx = (np.random.uniform(size=len(X)) <= 0.2)\n",
        "\n",
        "# Create training set (80% of the labelled data)\n",
        "X_trn = X[~validx]\n",
        "y_trn = yhat[~validx]\n",
        "\n",
        "# Create validation set (20% of the labelled data)\n",
        "X_val = X[validx]\n",
        "y_val = yhat[validx]\n",
        "\n",
        "# Create the test set\n",
        "X_tes = np.asarray(df_te,dtype=np.uint8).reshape(-1,28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYJm-qZ5X4sM",
        "colab_type": "text"
      },
      "source": [
        "# 3. Visualize some of the data items\n",
        "1. import matplotlib\n",
        "2. Visualize the first few data items and verify the corresponding labels match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLmx7lQtX4sM",
        "colab_type": "code",
        "outputId": "1923c5f2-bd19-40a7-ef2e-5b87b526ed98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# Concatenate nvis images horizontally and visualize it using matplot lib\n",
        "import matplotlib.pyplot as plt\n",
        "nvis = 12\n",
        "plt.imshow(np.concatenate(X_trn[:nvis],axis=1),cmap='gray',vmin=0,vmax=1)\n",
        "plt.show()\n",
        "\n",
        "# Print the corresponding labels to check they match\n",
        "y_trn[:nvis]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAA+CAYAAAAyPECXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFsANwzAK5f8KW9OLBZzWZgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3AZDjAeX4sP",
        "colab_type": "text"
      },
      "source": [
        "# 4a. Create a fully connected neural network in pytorch\n",
        "\n",
        "We follow the same steps as in [assignment 4](https://github.com/dilthoms/ai-ml-assignments/blob/master/AI-ML-Libs/sklearn-pytorch.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaKRhtfYX4sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "    \n",
        "# Create a class and define the layers in the __init__\n",
        "# and implement the forward propagation. Pytorch will automatically\n",
        "# calculate the backward propagation for you. \n",
        "\n",
        "class SingleHidden_NN(nn.Module):\n",
        "    '''\n",
        "    A Neural Network with a single hidden layer.\n",
        "    ''' \n",
        "    \n",
        "    # Create a constructor and define the layers and activations\n",
        "    def __init__(self, input_size,hidden_size,output_size):\n",
        "        '''\n",
        "        Arguments:\n",
        "            input_size  : The number of neurons in the input layer\n",
        "            hidden_size : The number of neurons in the hidden layer\n",
        "            output_size : The number of neurons in the output layer\n",
        "        '''\n",
        "        super(SingleHidden_NN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.layernorm1 = nn.LayerNorm(input_size)\n",
        "        # Define a pytorch linear layer that connects the input layer to the hidden layer\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        # Define a pytorch linear layer that connects the hidden layer to the output layer\n",
        "        self.layernorm2 = nn.LayerNorm(hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "\n",
        "         \n",
        "    def forward(self, x):\n",
        "      '''\n",
        "      Implement forward propagation with relu activation for the hidden layer.\n",
        "      Arguments:\n",
        "          x      : The input x\n",
        "      Returns:\n",
        "          output : The linear activation from the output layer\n",
        "      '''\n",
        "      output = self.layer2(self.layernorm2(F.relu(self.layer1(self.layernorm1(x.view(-1,self.input_size))))))\n",
        "      return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1_85DWsjLFk",
        "colab_type": "text"
      },
      "source": [
        "# 4b. Create a convolutional neural network in pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax4GKVH2jNk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ConvNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(ConvNN, self).__init__()\n",
        "      self.conv0_bn = nn.BatchNorm2d(1)\n",
        "      self.conv1 = nn.Conv2d(1,64,3,padding=1)\n",
        "      self.conv11 = nn.Conv2d(64,64,3,padding=1)\n",
        "      self.conv1_bn = nn.BatchNorm2d(64)\n",
        "      self.conv11_bn = nn.BatchNorm2d(64)\n",
        "      self.conv1l_bn = nn.BatchNorm2d(64)\n",
        "      self.conv2 = nn.Conv2d(64,128,3,padding=1)\n",
        "      self.conv22 = nn.Conv2d(128,128,3,padding=1)\n",
        "      self.conv2_bn = nn.BatchNorm2d(128)\n",
        "      self.conv22_bn = nn.BatchNorm2d(128)\n",
        "      self.conv2l_bn = nn.BatchNorm2d(128)\n",
        "      self.conv3 = nn.Conv2d(128,256,3,padding=1)\n",
        "      self.conv33 = nn.Conv2d(256,256,3,padding=1)\n",
        "      self.conv3_bn = nn.BatchNorm2d(256)\n",
        "      self.conv33_bn = nn.BatchNorm2d(256)\n",
        "      self.conv3l_bn = nn.BatchNorm2d(256)\n",
        "      self.locpool1 = nn.Conv2d(64,64,2,2,padding=0)\n",
        "      self.locpool2 = nn.Conv2d(128,128,2,2,padding=0)\n",
        "      self.locpool3 = nn.Conv2d(256,256,2,2,padding=0)\n",
        "      self.glopool = nn.AdaptiveMaxPool2d((1,1))\n",
        "      self.dropout = nn.Dropout(0.5)\n",
        "      self.layernorm1 = nn.LayerNorm(2048)\n",
        "      self.lin1 = nn.Linear(256,256)\n",
        "      self.layernorm2 = nn.LayerNorm(256)\n",
        "      self.lin2 = nn.Linear(256,10)\n",
        "      \n",
        "    def forward(self,x):\n",
        "      #print(x.shape)\n",
        "      #x = x.permute(0,3,2,1)\n",
        "      x = self.conv1_bn(F.relu(self.conv1((x))))\n",
        "      x = self.conv11_bn(F.relu(self.conv11((x))))\n",
        "      x = self.conv1l_bn(F.relu(self.locpool1(x)))\n",
        "      x = self.conv2_bn(F.relu(self.conv2(x)))\n",
        "      x = self.conv22_bn(F.relu(self.conv22(x)))\n",
        "      x = self.conv2l_bn(F.relu(self.locpool2(x)))\n",
        "      x = self.conv3_bn(F.relu(self.conv3(x)))\n",
        "      x = self.conv33_bn(F.relu(self.conv33(x)))\n",
        "      x = self.conv3l_bn(F.relu(self.locpool3(x)))\n",
        "      x = F.adaptive_avg_pool2d(x,(1,1))\n",
        "      x = x.view(x.size(0),-1)\n",
        "      x = F.relu(self.lin1(self.dropout(((x)))))\n",
        "      x = self.lin2(self.dropout(((x))))\n",
        "      return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyAd5JYtX4sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Dataset subclass for loading datasets in numpy arrays\n",
        "# See https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "import PIL \n",
        "import numpy as np\n",
        "class Numpy_XY_Dataset(Dataset):\n",
        "  '''\n",
        "  Dataset subclass for the MNIST digits dataset\n",
        "  '''\n",
        "  \n",
        "  def __init__(self,X,y,train=True):\n",
        "    '''\n",
        "    Create the independent and dependent variables\n",
        "    '''\n",
        "    super(Numpy_XY_Dataset,self).__init__()\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    assert(len(X)==len(y))\n",
        "    self.train = train\n",
        "    self.trtsfm = transforms.Compose([transforms.RandomAffine(degrees=5,shear=5,scale=(0.95,1.05)),transforms.ToTensor(),transforms.RandomErasing()])\n",
        "    self.tetsfm = transforms.Compose([transforms.ToTensor()])\n",
        "    \n",
        "  def __len__(self):\n",
        "    '''\n",
        "    Return the size of the dataset\n",
        "    '''\n",
        "    return len(self.X)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    '''\n",
        "    Return the data item at index idx\n",
        "    '''\n",
        "    if self.train:\n",
        "      return self.trtsfm(PIL.Image.fromarray(self.X[idx])),self.y[idx]\n",
        "      #return self.X[idx],self.y[idx]\n",
        "    else:\n",
        "      return self.tetsfm(PIL.Image.fromarray(self.X[idx])),self.y[idx]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Pcr-vfX4sb",
        "colab_type": "code",
        "outputId": "3053760f-6633-4c69-93f4-fc7b8cb9e83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write training loop\n",
        "import torch.optim as optim\n",
        "num_epochs = 50\n",
        "model = ConvNN().cuda()\n",
        "lossFunction = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=15)\n",
        "ds_trn = Numpy_XY_Dataset(X_trn,y_trn,train=True)\n",
        "ds_val = Numpy_XY_Dataset(X_val,y_val,train=False)\n",
        "\n",
        "dl_trn = DataLoader(dataset=ds_trn,batch_size=256,shuffle=True)\n",
        "dl_val = DataLoader(dataset=ds_val,batch_size=256,shuffle=False)\n",
        "\n",
        "# Write the training loop\n",
        "best = 0\n",
        "for epoch in range(num_epochs):\n",
        "  scheduler.step()\n",
        "  model.train(True) \n",
        "  for imgs,labels in dl_trn:\n",
        "    imgs,labels = imgs.cuda(),labels.cuda()\n",
        "    # Calculate the activations for the training set using forward propagation\n",
        "    out = model(imgs)\n",
        "    \n",
        "    # Calculate the value of loss using the output of the forward propagation and the \n",
        "    # ground truth for the training set\n",
        "    loss = lossFunction(out,labels)\n",
        "    \n",
        "    # Reset the gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Run the backward propagation and update the parameters by one step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "  model.train(False)\n",
        "  correct = 0\n",
        "  for imgs,labels in dl_val:\n",
        "    imgs,labels = imgs.cuda(),labels.cuda()\n",
        "    out = model(imgs)\n",
        "    valloss = lossFunction(out,labels)\n",
        "    _,out = torch.max(out,1)\n",
        "    correct += torch.sum(out == labels.data)\n",
        "  acc =  correct.float()/len(ds_val)\n",
        "  if acc > best:\n",
        "    best = acc\n",
        "    torch.save(model.state_dict(),\"digit-\"+str(np.round(acc.cpu().numpy(),decimals=5))+\".pth\")\n",
        "  print('Epoch [{}/{}], Train loss: {:.4f}' .format(epoch, num_epochs, loss.item()))\n",
        "  print('Epoch [{}/{}], Val loss: {:.4f} and acc: {:.4f}' .format(epoch, num_epochs, valloss, acc))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/50], Train loss: 0.4098\n",
            "Epoch [0/50], Val loss: 0.1761 and acc: 0.9437\n",
            "Epoch [1/50], Train loss: 0.4031\n",
            "Epoch [1/50], Val loss: 0.2704 and acc: 0.9372\n",
            "Epoch [2/50], Train loss: 0.1115\n",
            "Epoch [2/50], Val loss: 0.1433 and acc: 0.9782\n",
            "Epoch [3/50], Train loss: 0.2689\n",
            "Epoch [3/50], Val loss: 0.0958 and acc: 0.9824\n",
            "Epoch [4/50], Train loss: 0.4383\n",
            "Epoch [4/50], Val loss: 0.0957 and acc: 0.9886\n",
            "Epoch [5/50], Train loss: 0.1408\n",
            "Epoch [5/50], Val loss: 0.0904 and acc: 0.9881\n",
            "Epoch [6/50], Train loss: 0.0688\n",
            "Epoch [6/50], Val loss: 0.1071 and acc: 0.9856\n",
            "Epoch [7/50], Train loss: 0.1206\n",
            "Epoch [7/50], Val loss: 0.0650 and acc: 0.9892\n",
            "Epoch [8/50], Train loss: 0.0806\n",
            "Epoch [8/50], Val loss: 0.0440 and acc: 0.9814\n",
            "Epoch [9/50], Train loss: 0.3952\n",
            "Epoch [9/50], Val loss: 0.0314 and acc: 0.9901\n",
            "Epoch [10/50], Train loss: 0.1119\n",
            "Epoch [10/50], Val loss: 0.0585 and acc: 0.9905\n",
            "Epoch [11/50], Train loss: 0.4038\n",
            "Epoch [11/50], Val loss: 0.0625 and acc: 0.9887\n",
            "Epoch [12/50], Train loss: 0.1237\n",
            "Epoch [12/50], Val loss: 0.0409 and acc: 0.9892\n",
            "Epoch [13/50], Train loss: 0.0306\n",
            "Epoch [13/50], Val loss: 0.0342 and acc: 0.9903\n",
            "Epoch [14/50], Train loss: 0.0822\n",
            "Epoch [14/50], Val loss: 0.0270 and acc: 0.9932\n",
            "Epoch [15/50], Train loss: 0.1246\n",
            "Epoch [15/50], Val loss: 0.0374 and acc: 0.9933\n",
            "Epoch [16/50], Train loss: 0.0064\n",
            "Epoch [16/50], Val loss: 0.0265 and acc: 0.9934\n",
            "Epoch [17/50], Train loss: 0.1074\n",
            "Epoch [17/50], Val loss: 0.0401 and acc: 0.9936\n",
            "Epoch [18/50], Train loss: 0.0615\n",
            "Epoch [18/50], Val loss: 0.0387 and acc: 0.9942\n",
            "Epoch [19/50], Train loss: 0.0141\n",
            "Epoch [19/50], Val loss: 0.0257 and acc: 0.9939\n",
            "Epoch [20/50], Train loss: 0.0498\n",
            "Epoch [20/50], Val loss: 0.0333 and acc: 0.9938\n",
            "Epoch [21/50], Train loss: 0.0879\n",
            "Epoch [21/50], Val loss: 0.0355 and acc: 0.9936\n",
            "Epoch [22/50], Train loss: 0.0586\n",
            "Epoch [22/50], Val loss: 0.0365 and acc: 0.9938\n",
            "Epoch [23/50], Train loss: 0.0171\n",
            "Epoch [23/50], Val loss: 0.0311 and acc: 0.9938\n",
            "Epoch [24/50], Train loss: 0.0372\n",
            "Epoch [24/50], Val loss: 0.0312 and acc: 0.9937\n",
            "Epoch [25/50], Train loss: 0.0669\n",
            "Epoch [25/50], Val loss: 0.0489 and acc: 0.9939\n",
            "Epoch [26/50], Train loss: 0.1441\n",
            "Epoch [26/50], Val loss: 0.0360 and acc: 0.9940\n",
            "Epoch [27/50], Train loss: 0.0144\n",
            "Epoch [27/50], Val loss: 0.0384 and acc: 0.9939\n",
            "Epoch [28/50], Train loss: 0.0550\n",
            "Epoch [28/50], Val loss: 0.0459 and acc: 0.9938\n",
            "Epoch [29/50], Train loss: 0.0799\n",
            "Epoch [29/50], Val loss: 0.0459 and acc: 0.9939\n",
            "Epoch [30/50], Train loss: 0.0420\n",
            "Epoch [30/50], Val loss: 0.0453 and acc: 0.9942\n",
            "Epoch [31/50], Train loss: 0.0330\n",
            "Epoch [31/50], Val loss: 0.0437 and acc: 0.9939\n",
            "Epoch [32/50], Train loss: 0.0489\n",
            "Epoch [32/50], Val loss: 0.0467 and acc: 0.9938\n",
            "Epoch [33/50], Train loss: 0.0165\n",
            "Epoch [33/50], Val loss: 0.0453 and acc: 0.9939\n",
            "Epoch [34/50], Train loss: 0.0680\n",
            "Epoch [34/50], Val loss: 0.0382 and acc: 0.9943\n",
            "Epoch [35/50], Train loss: 0.0626\n",
            "Epoch [35/50], Val loss: 0.0407 and acc: 0.9939\n",
            "Epoch [36/50], Train loss: 0.1188\n",
            "Epoch [36/50], Val loss: 0.0432 and acc: 0.9939\n",
            "Epoch [37/50], Train loss: 0.0413\n",
            "Epoch [37/50], Val loss: 0.0394 and acc: 0.9942\n",
            "Epoch [38/50], Train loss: 0.0156\n",
            "Epoch [38/50], Val loss: 0.0365 and acc: 0.9943\n",
            "Epoch [39/50], Train loss: 0.0581\n",
            "Epoch [39/50], Val loss: 0.0316 and acc: 0.9942\n",
            "Epoch [40/50], Train loss: 0.1363\n",
            "Epoch [40/50], Val loss: 0.0322 and acc: 0.9940\n",
            "Epoch [41/50], Train loss: 0.0040\n",
            "Epoch [41/50], Val loss: 0.0367 and acc: 0.9939\n",
            "Epoch [42/50], Train loss: 0.0465\n",
            "Epoch [42/50], Val loss: 0.0333 and acc: 0.9943\n",
            "Epoch [43/50], Train loss: 0.0252\n",
            "Epoch [43/50], Val loss: 0.0340 and acc: 0.9943\n",
            "Epoch [44/50], Train loss: 0.0247\n",
            "Epoch [44/50], Val loss: 0.0287 and acc: 0.9942\n",
            "Epoch [45/50], Train loss: 0.0715\n",
            "Epoch [45/50], Val loss: 0.0255 and acc: 0.9942\n",
            "Epoch [46/50], Train loss: 0.0087\n",
            "Epoch [46/50], Val loss: 0.0287 and acc: 0.9942\n",
            "Epoch [47/50], Train loss: 0.0877\n",
            "Epoch [47/50], Val loss: 0.0342 and acc: 0.9945\n",
            "Epoch [48/50], Train loss: 0.1347\n",
            "Epoch [48/50], Val loss: 0.0299 and acc: 0.9942\n",
            "Epoch [49/50], Train loss: 0.0150\n",
            "Epoch [49/50], Val loss: 0.0313 and acc: 0.9943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9vyTKB_-nzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "0a7ac845-9302-45fb-9137-dc8cb451d46d"
      },
      "source": [
        "model = ConvNN()\n",
        "fn = \"digit-\"+str(np.round(best.cpu().numpy(),decimals=5))+\".pth\"\n",
        "print(fn)\n",
        "model.load_state_dict(torch.load(fn))\n",
        "model.eval()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "digit-0.99452.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNN(\n",
              "  (conv0_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv11_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv1l_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv22_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2l_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv33_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3l_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (locpool1): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (locpool2): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (locpool3): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (glopool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (layernorm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "  (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (layernorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "  (lin2): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAuEY_PRoD2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate predictions using the trained model\n",
        "# A hack for dataloader for X_tes by passing zeros as labels\n",
        "model = model.cuda()\n",
        "ds_tes = Numpy_XY_Dataset(X_tes,np.zeros(len(X_tes)),train=False)\n",
        "dl_tes = DataLoader(dataset=ds_tes,batch_size=256,shuffle=False)\n",
        "res = []\n",
        "for imgs,labels in dl_tes:\n",
        "    imgs,labels = imgs.cuda(),labels.cuda()\n",
        "    out = model(imgs)\n",
        "    _,out = torch.max(out,1)\n",
        "    res += (out.cpu().numpy().tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_SI7RHOX4se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the results to a pandas dataframe\n",
        "sub = pd.DataFrame({\"ImageId\":np.arange(1,28001),\"Label\":res})\n",
        "\n",
        "# Create the submission csv file from the dataframe\n",
        "sub.to_csv(\"sub.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Bw8d7_X4sg",
        "colab_type": "code",
        "outputId": "8f5d70af-08d0-4200-90db-475058be365d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Submit the csv file to kaggle using the kaggle api\n",
        "!kaggle competitions submit -c digit-recognizer -f sub.csv -m \"submission_bn2\"\n",
        "\n"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 208k/208k [00:03<00:00, 70.5kB/s]\n",
            "403 - Your team has used its submission allowance (5 of 5). This resets at midnight UTC (5.4 hours from now).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE9E05D8ZuFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "dc2234d2-c877-410b-84fe-559432989d56"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\t   digit-0.97271.pth  digit-0.98486.pth  digit-0.9919.pth\n",
            "digit-0.11621.pth  digit-0.97318.pth  digit-0.98498.pth  digit-0.99201.pth\n",
            "digit-0.18272.pth  digit-0.9739.pth   digit-0.9851.pth\t digit-0.99213.pth\n",
            "digit-0.23909.pth  digit-0.97449.pth  digit-0.9857.pth\t digit-0.99225.pth\n",
            "digit-0.27092.pth  digit-0.97461.pth  digit-0.98653.pth  digit-0.99237.pth\n",
            "digit-0.5143.pth   digit-0.97473.pth  digit-0.98665.pth  digit-0.99249.pth\n",
            "digit-0.74338.pth  digit-0.97545.pth  digit-0.98677.pth  digit-0.99261.pth\n",
            "digit-0.83135.pth  digit-0.97557.pth  digit-0.98713.pth  digit-0.99273.pth\n",
            "digit-0.87783.pth  digit-0.97604.pth  digit-0.98737.pth  digit-0.99285.pth\n",
            "digit-0.90262.pth  digit-0.9764.pth   digit-0.98749.pth  digit-0.99297.pth\n",
            "digit-0.91836.pth  digit-0.97664.pth  digit-0.98796.pth  digit-0.99309.pth\n",
            "digit-0.93051.pth  digit-0.97771.pth  digit-0.98808.pth  digit-0.99321.pth\n",
            "digit-0.93647.pth  digit-0.97807.pth  digit-0.98832.pth  digit-0.99333.pth\n",
            "digit-0.94207.pth  digit-0.97831.pth  digit-0.98844.pth  digit-0.99344.pth\n",
            "digit-0.94672.pth  digit-0.9789.pth   digit-0.98856.pth  digit-0.99356.pth\n",
            "digit-0.95101.pth  digit-0.97962.pth  digit-0.9888.pth\t digit-0.99368.pth\n",
            "digit-0.95447.pth  digit-0.97986.pth  digit-0.98892.pth  digit-0.9938.pth\n",
            "digit-0.95507.pth  digit-0.98045.pth  digit-0.98903.pth  digit-0.99392.pth\n",
            "digit-0.95709.pth  digit-0.98057.pth  digit-0.98915.pth  digit-0.99404.pth\n",
            "digit-0.95805.pth  digit-0.98093.pth  digit-0.98951.pth  digit-0.99416.pth\n",
            "digit-0.96103.pth  digit-0.98105.pth  digit-0.98963.pth  digit-0.99428.pth\n",
            "digit-0.96305.pth  digit-0.98117.pth  digit-0.98987.pth  digit-0.9944.pth\n",
            "digit-0.96341.pth  digit-0.98141.pth  digit-0.98999.pth  digit-0.99452.pth\n",
            "digit-0.96472.pth  digit-0.98153.pth  digit-0.99011.pth  digit-0.99464.pth\n",
            "digit-0.96484.pth  digit-0.98164.pth  digit-0.99023.pth  digit-0.99476.pth\n",
            "digit-0.96627.pth  digit-0.98236.pth  digit-0.99035.pth  digit-0.99487.pth\n",
            "digit-0.96639.pth  digit-0.98248.pth  digit-0.99046.pth  digit-0.99499.pth\n",
            "digit-0.96722.pth  digit-0.98284.pth  digit-0.99058.pth  digit-0.99511.pth\n",
            "digit-0.96818.pth  digit-0.98296.pth  digit-0.99082.pth  digit-0.99523.pth\n",
            "digit-0.96853.pth  digit-0.98319.pth  digit-0.99094.pth  sample_data\n",
            "digit-0.96865.pth  digit-0.98343.pth  digit-0.99106.pth  sample_submission.csv\n",
            "digit-0.96949.pth  digit-0.98355.pth  digit-0.99118.pth  sub.csv\n",
            "digit-0.96985.pth  digit-0.98367.pth  digit-0.9913.pth\t test.csv\n",
            "digit-0.97092.pth  digit-0.98379.pth  digit-0.99142.pth  test.csv.zip\n",
            "digit-0.97116.pth  digit-0.98439.pth  digit-0.99154.pth  train.csv\n",
            "digit-0.97235.pth  digit-0.98451.pth  digit-0.99166.pth  train.csv.zip\n",
            "digit-0.97247.pth  digit-0.98462.pth  digit-0.99178.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaNSGZUD-gsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18741505-4b69-48d7-dbb6-a92aff38a84a"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1125408\n",
            "-rw-r--r-- 1 root root 76775041 Dec 11 20:01 train.csv\n",
            "-rw-r--r-- 1 root root 51118296 Dec 11 20:01 test.csv\n",
            "drwxr-xr-x 1 root root     4096 Dec 18 16:52 sample_data\n",
            "-rw-r--r-- 1 root root     2608 Jan 12 15:48 adc.json\n",
            "-rw-r--r-- 1 root root  9606023 Jan 12 15:48 train.csv.zip\n",
            "-rw-r--r-- 1 root root  6385593 Jan 12 15:48 test.csv.zip\n",
            "-rw-r--r-- 1 root root   240909 Jan 12 15:48 sample_submission.csv\n",
            "-rw-r--r-- 1 root root  2604224 Jan 12 16:00 digit-0.97807.pth\n",
            "-rw-r--r-- 1 root root  2604224 Jan 12 16:00 digit-0.98343.pth\n",
            "-rw-r--r-- 1 root root  5995549 Jan 12 16:11 digit-0.97271.pth\n",
            "-rw-r--r-- 1 root root  5995549 Jan 12 16:11 digit-0.98248.pth\n",
            "-rw-r--r-- 1 root root  5995549 Jan 12 16:11 digit-0.98677.pth\n",
            "-rw-r--r-- 1 root root  5995521 Jan 12 16:19 digit-0.97092.pth\n",
            "-rw-r--r-- 1 root root  5995521 Jan 12 16:19 digit-0.98236.pth\n",
            "-rw-r--r-- 1 root root  5995521 Jan 12 16:19 digit-0.98451.pth\n",
            "-rw-r--r-- 1 root root  5995521 Jan 12 16:19 digit-0.9919.pth\n",
            "-rw-r--r-- 1 root root  5995503 Jan 12 16:22 digit-0.97247.pth\n",
            "-rw-r--r-- 1 root root  5995503 Jan 12 16:22 digit-0.98462.pth\n",
            "-rw-r--r-- 1 root root  5995517 Jan 12 16:24 digit-0.96639.pth\n",
            "-rw-r--r-- 1 root root  5995517 Jan 12 16:24 digit-0.98153.pth\n",
            "-rw-r--r-- 1 root root  5995533 Jan 12 16:27 digit-0.96472.pth\n",
            "-rw-r--r-- 1 root root  5995533 Jan 12 16:27 digit-0.98355.pth\n",
            "-rw-r--r-- 1 root root  5995533 Jan 12 16:28 digit-0.99094.pth\n",
            "-rw-r--r-- 1 root root  7044109 Jan 12 16:34 digit-0.97318.pth\n",
            "-rw-r--r-- 1 root root  7044109 Jan 12 16:35 digit-0.98379.pth\n",
            "-rw-r--r-- 1 root root  7044109 Jan 12 16:35 digit-0.99058.pth\n",
            "-rw-r--r-- 1 root root  7044109 Jan 12 16:35 digit-0.9913.pth\n",
            "-rw-r--r-- 1 root root  7044095 Jan 12 16:39 digit-0.96949.pth\n",
            "-rw-r--r-- 1 root root  7044095 Jan 12 16:39 digit-0.9764.pth\n",
            "-rw-r--r-- 1 root root  7044095 Jan 12 16:39 digit-0.98903.pth\n",
            "-rw-r--r-- 1 root root  7044095 Jan 12 16:39 digit-0.98951.pth\n",
            "-rw-r--r-- 1 root root  7044095 Jan 12 16:40 digit-0.99201.pth\n",
            "-rw-r--r-- 1 root root  7044095 Jan 12 16:40 digit-0.99273.pth\n",
            "-rw-r--r-- 1 root root  7044081 Jan 12 16:43 digit-0.98164.pth\n",
            "-rw-r--r-- 1 root root  7044081 Jan 12 16:43 digit-0.98737.pth\n",
            "-rw-r--r-- 1 root root  7044081 Jan 12 16:43 digit-0.98749.pth\n",
            "-rw-r--r-- 1 root root  7044081 Jan 12 16:44 digit-0.99487.pth\n",
            "-rw-r--r-- 1 root root  7044081 Jan 12 16:45 digit-0.99499.pth\n",
            "-rw-r--r-- 1 root root  7044081 Jan 12 16:45 digit-0.99511.pth\n",
            "-rw-r--r-- 1 root root  7044081 Jan 12 16:45 digit-0.99523.pth\n",
            "-rw-r--r-- 1 root root  7044097 Jan 12 16:52 digit-0.96341.pth\n",
            "-rw-r--r-- 1 root root  7044097 Jan 12 16:52 digit-0.9851.pth\n",
            "-rw-r--r-- 1 root root  7044097 Jan 12 16:52 digit-0.99023.pth\n",
            "-rw-r--r-- 1 root root  7044097 Jan 12 16:52 digit-0.99154.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.5143.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.74338.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.83135.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.87783.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.90262.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.91836.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.93051.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.93647.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.94207.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.94672.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.95101.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:56 digit-0.95447.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.95805.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96103.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96305.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96484.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96627.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96722.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96818.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96853.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.96985.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.97116.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.97235.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.9739.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:57 digit-0.97557.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.97604.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.97664.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.97771.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.9789.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.97962.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.97986.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.98057.pth\n",
            "-rw-r--r-- 1 root root  7044105 Jan 12 16:58 digit-0.98141.pth\n",
            "-rw-r--r-- 1 root root  7044077 Jan 12 17:01 digit-0.9857.pth\n",
            "-rw-r--r-- 1 root root  7044077 Jan 12 17:03 digit-0.99452.pth\n",
            "-rw-r--r-- 1 root root  7044077 Jan 12 17:03 digit-0.99464.pth\n",
            "-rw-r--r-- 1 root root  7044087 Jan 12 17:04 digit-0.98105.pth\n",
            "-rw-r--r-- 1 root root  7044087 Jan 12 17:05 digit-0.98319.pth\n",
            "-rw-r--r-- 1 root root  7044087 Jan 12 17:05 digit-0.98796.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:10 digit-0.98486.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:10 digit-0.98665.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:10 digit-0.99011.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:10 digit-0.99166.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:11 digit-0.99249.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:11 digit-0.99261.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:13 digit-0.98284.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:13 digit-0.98999.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:13 digit-0.99082.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:13 digit-0.99213.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:14 digit-0.99368.pth\n",
            "-rw-r--r-- 1 root root  7060231 Jan 12 17:15 digit-0.99476.pth\n",
            "-rw-r--r-- 1 root root  7060251 Jan 12 17:32 digit-0.97473.pth\n",
            "-rw-r--r-- 1 root root  7060251 Jan 12 17:32 digit-0.98856.pth\n",
            "-rw-r--r-- 1 root root  7060251 Jan 12 17:32 digit-0.98987.pth\n",
            "-rw-r--r-- 1 root root  7060251 Jan 12 17:33 digit-0.99035.pth\n",
            "-rw-r--r-- 1 root root  7060251 Jan 12 17:33 digit-0.99237.pth\n",
            "-rw-r--r-- 1 root root  7060251 Jan 12 17:34 digit-0.99309.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:38 digit-0.97461.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:38 digit-0.98117.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:39 digit-0.98844.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:40 digit-0.99046.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:40 digit-0.99178.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:40 digit-0.99297.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:40 digit-0.99344.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:42 digit-0.99392.pth\n",
            "-rw-r--r-- 1 root root  7060249 Jan 12 17:42 digit-0.99404.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:45 digit-0.97449.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:45 digit-0.98045.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:45 digit-0.98367.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:45 digit-0.98808.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:45 digit-0.98832.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:46 digit-0.98915.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:46 digit-0.99118.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:47 digit-0.99142.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:47 digit-0.99321.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:47 digit-0.99333.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:47 digit-0.9938.pth\n",
            "-rw-r--r-- 1 root root  6011657 Jan 12 17:48 digit-0.99416.pth\n",
            "-rw-r--r-- 1 root root 32232325 Jan 12 18:02 digit-0.11621.pth\n",
            "-rw-r--r-- 1 root root 18862991 Jan 12 18:04 digit-0.18272.pth\n",
            "-rw-r--r-- 1 root root 18862991 Jan 12 18:04 digit-0.23909.pth\n",
            "-rw-r--r-- 1 root root 18862991 Jan 12 18:04 digit-0.27092.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:05 digit-0.95507.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:05 digit-0.97545.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:06 digit-0.98093.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:06 digit-0.98439.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:06 digit-0.98653.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:06 digit-0.98713.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:07 digit-0.98892.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:07 digit-0.99285.pth\n",
            "-rw-r--r-- 1 root root  8377217 Jan 12 18:07 digit-0.99356.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:09 digit-0.95709.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:09 digit-0.96865.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:09 digit-0.97831.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:09 digit-0.98296.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:09 digit-0.98498.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:09 digit-0.9888.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:10 digit-0.98963.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:10 digit-0.99106.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:11 digit-0.99225.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:11 digit-0.99428.pth\n",
            "-rw-r--r-- 1 root root  6280093 Jan 12 18:11 digit-0.9944.pth\n",
            "-rw-r--r-- 1 root root   212908 Jan 12 18:16 sub.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q199rH_M_XCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}