{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of kaggle-digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilthoms/ai-ml-assignments/blob/master/kaggle/kaggle-digits/kaggle-digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "soMh_oOhlHD3"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Setup kaggle cli and download dataset in google colab\n",
        "\n",
        "Since all data is lost when google colab session ends, the six steps given below will download dataset from kaggle and save you from the trouble of downloading the dataset everytime. The first two steps below have to be done manually the first time. After that the rest of the steps can be executed by running the three cells (steps 3-6) below. You have to run these three cells to download the dataset everytime you start a new session. \n",
        "  \n",
        "\n",
        "1. Download / create json credentials after creating an account in kaggle.  See https://github.com/Kaggle/kaggle-api for more details\n",
        "2. Upload the kaggle.json file to your google drive\n",
        "3. Run the script in the first cell below to download kaggle.json  to your colab environment\n",
        "4. It will ask you to click on a link and enter the verification code\n",
        "5. Install kaggle cli using pip install\n",
        "6. Download the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zUM5cK52lHD6",
        "outputId": "8b86c2e8-8987-44f3-dd98-2e8979efc343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Code from https://medium.com/@move37timm/using-kaggle-api-for-google-colaboratory-d18645f93648\n",
        "# Create kaggle.json by following instructions at https://github.com/Kaggle/kaggle-api\n",
        "# Upload kaggle.json to google drive\n",
        "# Download kaggle.json to colab from the users google drive\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "if not os.path.exists(os.path.dirname(filename)):\n",
        "  os.makedirs(os.path.dirname(filename))\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9KPWpND0lHD-",
        "outputId": "41c6470e-73dc-4b5a-b8a3-4dcf6432ce06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Install kaggle cli\n",
        "!pip install kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kBU3yAwLlHEB",
        "outputId": "911a4f70-e825-4c31-ad8c-f8af57949c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the dataset for digit-recognizer chalenge\n",
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZxHZ6ewrX4sA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Read data in pandas dataframe\n",
        "1. Check train and test csv files have been downloaded\n",
        "2. import pandas and numpy and create train and test dataframes from the respective csv files\n",
        "3. Inspect the dataframes\n",
        "4. Convert to numpy arrays for train, validation, and test set "
      ]
    },
    {
      "metadata": {
        "id": "SQ8a8xpkX4sB",
        "colab_type": "code",
        "outputId": "0be3e37f-6916-426b-e364-ccf40a5c119e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "# Check train and test csv files exist\n",
        "!ls -ltr"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 246548\n",
            "drwxr-xr-x 1 root root     4096 Apr  4 20:20 sample_data\n",
            "-rw-r--r-- 1 root root     2520 Apr 19 11:43 adc.json\n",
            "-rw-r--r-- 1 root root 76775041 Apr 19 11:44 train.csv\n",
            "-rw-r--r-- 1 root root 51118296 Apr 19 11:44 test.csv\n",
            "-rw-r--r-- 1 root root   240909 Apr 19 11:44 sample_submission.csv\n",
            "-rw-r--r-- 1 root root   325791 Apr 19 11:47 digit-0.96612.pth\n",
            "-rw-r--r-- 1 root root   325791 Apr 19 11:49 digit-0.97785.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.96055.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.97903.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.98069.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.98389.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.98721.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.98768.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.98792.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.9891.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.99017.pth\n",
            "-rw-r--r-- 1 root root   326142 Apr 19 11:55 digit-0.99041.pth\n",
            "-rw-r--r-- 1 root root  4149129 Apr 19 11:57 digit-0.96506.pth\n",
            "-rw-r--r-- 1 root root  4149129 Apr 19 11:57 digit-0.9846.pth\n",
            "-rw-r--r-- 1 root root  4149129 Apr 19 11:57 digit-0.98685.pth\n",
            "-rw-r--r-- 1 root root  4149129 Apr 19 11:57 digit-0.99005.pth\n",
            "-rw-r--r-- 1 root root  4149129 Apr 19 11:58 digit-0.99289.pth\n",
            "-rw-r--r-- 1 root root  4149091 Apr 19 12:16 digit-0.96605.pth\n",
            "-rw-r--r-- 1 root root  4149091 Apr 19 12:16 digit-0.9814.pth\n",
            "-rw-r--r-- 1 root root  4149091 Apr 19 12:16 digit-0.98476.pth\n",
            "-rw-r--r-- 1 root root  4149151 Apr 19 12:16 digit-0.97385.pth\n",
            "-rw-r--r-- 1 root root  4149151 Apr 19 12:16 digit-0.98296.pth\n",
            "-rw-r--r-- 1 root root  4149151 Apr 19 12:16 digit-0.98824.pth\n",
            "-rw-r--r-- 1 root root  4149151 Apr 19 12:17 digit-0.9898.pth\n",
            "-rw-r--r-- 1 root root  4149151 Apr 19 12:17 digit-0.99148.pth\n",
            "-rw-r--r-- 1 root root  4149151 Apr 19 12:18 digit-0.99172.pth\n",
            "-rw-r--r-- 1 root root  4149151 Apr 19 12:18 digit-0.99244.pth\n",
            "-rw-r--r-- 1 root root  4152887 Apr 19 12:22 digit-0.97493.pth\n",
            "-rw-r--r-- 1 root root  4152887 Apr 19 12:22 digit-0.98656.pth\n",
            "-rw-r--r-- 1 root root  4152887 Apr 19 12:22 digit-0.98788.pth\n",
            "-rw-r--r-- 1 root root  4152887 Apr 19 12:22 digit-0.99016.pth\n",
            "-rw-r--r-- 1 root root  4152887 Apr 19 12:22 digit-0.99124.pth\n",
            "-rw-r--r-- 1 root root  4152887 Apr 19 12:23 digit-0.99232.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:25 digit-0.97768.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:25 digit-0.98512.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:25 digit-0.98848.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:25 digit-0.98872.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:26 digit-0.99004.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:26 digit-0.9916.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:26 digit-0.99184.pth\n",
            "-rw-r--r-- 1 root root  4152907 Apr 19 12:26 digit-0.9928.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EDRoZUpkX4sD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read the csv files using pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df_tr = pd.read_csv('train.csv')\n",
        "df_te = pd.read_csv('test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hg_CeJieX4sF",
        "colab_type": "code",
        "outputId": "43f9292d-1415-41b3-aba1-1f458a4e8c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "cell_type": "code",
      "source": [
        "# Examine the contents of train.csv\n",
        "# Contains 28x28 pixel values and the corresponding digit label\n",
        "print (df_tr.info())\n",
        "df_tr.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42000 entries, 0 to 41999\n",
            "Columns: 785 entries, label to pixel783\n",
            "dtypes: int64(785)\n",
            "memory usage: 251.5 MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "3      4       0       0       0       0       0       0       0       0   \n",
              "4      0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0       0    ...            0         0         0         0         0   \n",
              "1       0    ...            0         0         0         0         0   \n",
              "2       0    ...            0         0         0         0         0   \n",
              "3       0    ...            0         0         0         0         0   \n",
              "4       0    ...            0         0         0         0         0   \n",
              "\n",
              "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0         0  \n",
              "1         0         0         0         0         0  \n",
              "2         0         0         0         0         0  \n",
              "3         0         0         0         0         0  \n",
              "4         0         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "x3VnaQQmX4sH",
        "colab_type": "code",
        "outputId": "0db88d90-fe95-406d-fe9b-aa1d24b2bb06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "cell_type": "code",
      "source": [
        "# Examine the contents of test.csv\n",
        "# Contains only the 28x28 pixel values without the corresponding digit label\n",
        "print (df_te.info())\n",
        "df_te.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28000 entries, 0 to 27999\n",
            "Columns: 784 entries, pixel0 to pixel783\n",
            "dtypes: int64(784)\n",
            "memory usage: 167.5 MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0       0    ...            0         0         0         0         0   \n",
              "1       0    ...            0         0         0         0         0   \n",
              "2       0    ...            0         0         0         0         0   \n",
              "3       0    ...            0         0         0         0         0   \n",
              "4       0    ...            0         0         0         0         0   \n",
              "\n",
              "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0         0  \n",
              "1         0         0         0         0         0  \n",
              "2         0         0         0         0         0  \n",
              "3         0         0         0         0         0  \n",
              "4         0         0         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "sewFQiFaX4sK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Partition the training data into pixels (independent variable) and label (dependent variable)\n",
        "X = np.asarray(df_tr.drop('label',axis=1),dtype=np.float32).reshape(-1,28,28)/255.0\n",
        "yhat = np.asarray(df_tr['label'])\n",
        "\n",
        "np.random.seed(2)\n",
        "# Generate random indices for creating a random validation set with 20% of the labelled data\n",
        "validx = (np.random.uniform(size=len(X)) <= 0.2)\n",
        "\n",
        "# Create training set (80% of the labelled data)\n",
        "X_trn = X[~validx]\n",
        "y_trn = yhat[~validx]\n",
        "\n",
        "# Create validation set (20% of the labelled data)\n",
        "X_val = X[validx]\n",
        "y_val = yhat[validx]\n",
        "\n",
        "# Create the test set\n",
        "X_tes = np.asarray(df_te,dtype=np.float32).reshape(-1,28,28)/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AYJm-qZ5X4sM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Visualize some of the data items\n",
        "1. import matplotlib\n",
        "2. Visualize the first few data items and verify the corresponding labels match"
      ]
    },
    {
      "metadata": {
        "id": "zLmx7lQtX4sM",
        "colab_type": "code",
        "outputId": "23129f60-1e2c-469f-a2f7-fe80656b9f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "# Concatenate nvis images horizontally and visualize it using matplot lib\n",
        "import matplotlib.pyplot as plt\n",
        "nvis = 12\n",
        "plt.imshow(np.concatenate(X_trn[:nvis],axis=1),cmap='gray',vmin=0,vmax=1)\n",
        "plt.show()\n",
        "\n",
        "# Print the corresponding labels to check they match\n",
        "y_trn[:nvis]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA+CAYAAAA71+DtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpFIugn/D00bfqgxi153AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "K3AZDjAeX4sP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4a. Create a fully connected neural network in pytorch\n",
        "\n",
        "We follow the same steps as in [assignment 4](https://github.com/dilthoms/ai-ml-assignments/blob/master/AI-ML-Libs/sklearn-pytorch.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "LaKRhtfYX4sS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "    \n",
        "# Create a class and define the layers in the __init__\n",
        "# and implement the forward propagation. Pytorch will automatically\n",
        "# calculate the backward propagation for you. \n",
        "\n",
        "class SingleHidden_NN(nn.Module):\n",
        "    '''\n",
        "    A Neural Network with a single hidden layer.\n",
        "    ''' \n",
        "    \n",
        "    # Create a constructor and define the layers and activations\n",
        "    def __init__(self, input_size,hidden_size,output_size):\n",
        "        '''\n",
        "        Arguments:\n",
        "            input_size  : The number of neurons in the input layer\n",
        "            hidden_size : The number of neurons in the hidden layer\n",
        "            output_size : The number of neurons in the output layer\n",
        "        '''\n",
        "        super(SingleHidden_NN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.layernorm1 = nn.LayerNorm(input_size)\n",
        "        # Define a pytorch linear layer that connects the input layer to the hidden layer\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        # Define a pytorch linear layer that connects the hidden layer to the output layer\n",
        "        self.layernorm2 = nn.LayerNorm(hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "\n",
        "         \n",
        "    def forward(self, x):\n",
        "      '''\n",
        "      Implement forward propagation with relu activation for the hidden layer.\n",
        "      Arguments:\n",
        "          x      : The input x\n",
        "      Returns:\n",
        "          output : The linear activation from the output layer\n",
        "      '''\n",
        "      output = self.layer2(self.layernorm2(F.relu(self.layer1(self.layernorm1(x.view(-1,self.input_size))))))\n",
        "      return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P1_85DWsjLFk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4b. Create a convolutional neural network in pytorch\n"
      ]
    },
    {
      "metadata": {
        "id": "ax4GKVH2jNk-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class ConvNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(ConvNN, self).__init__()\n",
        "      self.conv0_bn = nn.BatchNorm2d(1)\n",
        "      self.conv1 = nn.Conv2d(1,64,5)\n",
        "      self.conv1_bn = nn.BatchNorm2d(64)\n",
        "      self.conv2 = nn.Conv2d(64,128,5)\n",
        "      self.conv2_bn = nn.BatchNorm2d(128)\n",
        "      self.conv3 = nn.Conv2d(128,256,5)\n",
        "      self.conv3_bn = nn.BatchNorm2d(256)\n",
        "      self.locpool = nn.MaxPool2d(2, 2)\n",
        "      self.glopool = nn.AdaptiveMaxPool2d((1,1))\n",
        "      self.dropout = nn.Dropout(0.5)\n",
        "      self.layernorm1 = nn.LayerNorm(256)\n",
        "      self.lin1 = nn.Linear(256,32)\n",
        "      self.layernorm2 = nn.LayerNorm(32)\n",
        "      self.lin2 = nn.Linear(32,10)\n",
        "      \n",
        "    def forward(self,x):\n",
        "      x = x.unsqueeze(-1).permute(0,3,2,1)\n",
        "      x = self.conv1_bn(F.relu(self.conv1(self.conv0_bn(x))))\n",
        "      x = self.locpool(self.conv2_bn(F.relu(self.conv2(x))))\n",
        "      x = F.adaptive_avg_pool2d(self.conv3_bn(F.relu(self.conv3(x))),(1, 1)).squeeze()\n",
        "      x = F.relu(self.lin1(self.dropout(self.layernorm1(x))))\n",
        "      x = self.lin2(self.dropout(self.layernorm2(x)))\n",
        "      return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zyAd5JYtX4sV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a Dataset subclass for loading datasets in numpy arrays\n",
        "# See https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Numpy_XY_Dataset(Dataset):\n",
        "  '''\n",
        "  Dataset subclass for the MNIST digits dataset\n",
        "  '''\n",
        "  \n",
        "  def __init__(self,X,y):\n",
        "    '''\n",
        "    Create the independent and dependent variables\n",
        "    '''\n",
        "    super(Numpy_XY_Dataset,self).__init__()\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    assert(len(X)==len(y))\n",
        "    \n",
        "  def __len__(self):\n",
        "    '''\n",
        "    Return the size of the dataset\n",
        "    '''\n",
        "    return len(self.X)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    '''\n",
        "    Return the data item at index idx\n",
        "    '''\n",
        "    return self.X[idx],self.y[idx]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-1Pcr-vfX4sb",
        "colab_type": "code",
        "outputId": "7d8b5f81-9a5d-4ffe-f637-af9a010a8d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "# Write training loop\n",
        "import torch.optim as optim\n",
        "num_epochs = 20\n",
        "model = ConvNN().cuda()\n",
        "lossFunction = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=5)\n",
        "ds_trn = Numpy_XY_Dataset(X_trn,y_trn)\n",
        "ds_val = Numpy_XY_Dataset(X_val,y_val)\n",
        "\n",
        "dl_trn = DataLoader(dataset=ds_trn,batch_size=256,shuffle=True)\n",
        "dl_val = DataLoader(dataset=ds_val,batch_size=256,shuffle=False)\n",
        "\n",
        "# Write the training loop\n",
        "best = 0\n",
        "for epoch in range(num_epochs):\n",
        "  scheduler.step()\n",
        "  model.train(True) \n",
        "  for imgs,labels in dl_trn:\n",
        "    imgs,labels = imgs.cuda(),labels.cuda()\n",
        "    # Calculate the activations for the training set using forward propagation\n",
        "    out = model(imgs)\n",
        "    \n",
        "    # Calculate the value of loss using the output of the forward propagation and the \n",
        "    # ground truth for the training set\n",
        "    loss = lossFunction(out,labels)\n",
        "    \n",
        "    # Reset the gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Run the backward propagation and update the parameters by one step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "  model.train(False)\n",
        "  correct = 0\n",
        "  for imgs,labels in dl_val:\n",
        "    imgs,labels = imgs.cuda(),labels.cuda()\n",
        "    out = model(imgs)\n",
        "    valloss = lossFunction(out,labels)\n",
        "    _,out = torch.max(out,1)\n",
        "    correct += torch.sum(out == labels.data)\n",
        "  acc =  correct.float()/len(ds_val)\n",
        "  if acc > best:\n",
        "    best = acc\n",
        "    torch.save(model.state_dict(),\"digit-\"+str(np.round(acc.cpu().numpy(),decimals=5))+\".pth\")\n",
        "  print('Epoch [{}/{}], Train loss: {:.4f}' .format(epoch, num_epochs, loss.item()))\n",
        "  print('Epoch [{}/{}], Val loss: {:.4f} and acc: {:.4f}' .format(epoch, num_epochs, valloss, acc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/20], Train loss: 0.1135\n",
            "Epoch [0/20], Val loss: 0.1261 and acc: 0.9692\n",
            "Epoch [1/20], Train loss: 0.1077\n",
            "Epoch [1/20], Val loss: 0.2204 and acc: 0.9737\n",
            "Epoch [2/20], Train loss: 0.0849\n",
            "Epoch [2/20], Val loss: 0.1176 and acc: 0.9868\n",
            "Epoch [3/20], Train loss: 0.1900\n",
            "Epoch [3/20], Val loss: 0.1019 and acc: 0.9826\n",
            "Epoch [4/20], Train loss: 0.0815\n",
            "Epoch [4/20], Val loss: 0.0920 and acc: 0.9887\n",
            "Epoch [5/20], Train loss: 0.0691\n",
            "Epoch [5/20], Val loss: 0.0656 and acc: 0.9918\n",
            "Epoch [6/20], Train loss: 0.0196\n",
            "Epoch [6/20], Val loss: 0.0694 and acc: 0.9927\n",
            "Epoch [7/20], Train loss: 0.0121\n",
            "Epoch [7/20], Val loss: 0.0415 and acc: 0.9930\n",
            "Epoch [8/20], Train loss: 0.1058\n",
            "Epoch [8/20], Val loss: 0.0564 and acc: 0.9940\n",
            "Epoch [9/20], Train loss: 0.0121\n",
            "Epoch [9/20], Val loss: 0.0368 and acc: 0.9942\n",
            "Epoch [10/20], Train loss: 0.0317\n",
            "Epoch [10/20], Val loss: 0.0521 and acc: 0.9948\n",
            "Epoch [11/20], Train loss: 0.0304\n",
            "Epoch [11/20], Val loss: 0.0417 and acc: 0.9946\n",
            "Epoch [12/20], Train loss: 0.0067\n",
            "Epoch [12/20], Val loss: 0.0403 and acc: 0.9945\n",
            "Epoch [13/20], Train loss: 0.1202\n",
            "Epoch [13/20], Val loss: 0.0358 and acc: 0.9946\n",
            "Epoch [14/20], Train loss: 0.0285\n",
            "Epoch [14/20], Val loss: 0.0449 and acc: 0.9945\n",
            "Epoch [15/20], Train loss: 0.0162\n",
            "Epoch [15/20], Val loss: 0.0383 and acc: 0.9946\n",
            "Epoch [16/20], Train loss: 0.0058\n",
            "Epoch [16/20], Val loss: 0.0420 and acc: 0.9946\n",
            "Epoch [17/20], Train loss: 0.0070\n",
            "Epoch [17/20], Val loss: 0.0424 and acc: 0.9945\n",
            "Epoch [18/20], Train loss: 0.0089\n",
            "Epoch [18/20], Val loss: 0.0373 and acc: 0.9945\n",
            "Epoch [19/20], Train loss: 0.0066\n",
            "Epoch [19/20], Val loss: 0.0365 and acc: 0.9948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SAuEY_PRoD2A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate predictions using the trained model\n",
        "# A hack for dataloader for X_tes by passing zeros as labels\n",
        "\n",
        "ds_tes = Numpy_XY_Dataset(X_tes,np.zeros(len(X_tes)))\n",
        "dl_tes = DataLoader(dataset=ds_tes,batch_size=256,shuffle=False)\n",
        "res = []\n",
        "for imgs,labels in dl_tes:\n",
        "    imgs,labels = imgs.cuda(),labels.cuda()\n",
        "    out = model(imgs)\n",
        "    _,out = torch.max(out,1)\n",
        "    res += (out.cpu().numpy().tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_SI7RHOX4se",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert the results to a pandas dataframe\n",
        "sub = pd.DataFrame({\"ImageId\":np.arange(1,28001),\"Label\":res})\n",
        "\n",
        "# Create the submission csv file from the dataframe\n",
        "sub.to_csv(\"sub.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0Bw8d7_X4sg",
        "colab_type": "code",
        "outputId": "f281f9a7-5734-408d-c23a-b5e394595f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Submit the csv file to kaggle using the kaggle api\n",
        "!kaggle competitions submit -c digit-recognizer -f sub.csv -m \"submission_bn2\"\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 208k/208k [00:05<00:00, 38.8kB/s]\n",
            "Successfully submitted to Digit Recognizer"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gE9E05D8ZuFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}